# Less conservative corrections are also included by Holm (1979) ("holm"),
# Hochberg (1988) ("hochberg"), Hommel (1988) ("hommel"),
# Benjamini & Hochberg (1995) ("BH" or its alias "fdr"),
# and Benjamini & Yekutieli (2001) ("BY"), respectively.
# Benjamini, Y., and Hochberg, Y. (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal Statistical Society Series B 57, 289–300.
#
# Benjamini, Y., and Yekutieli, D. (2001). The control of the false discovery rate in multiple testing under dependency. Annals of Statistics 29, 1165–1188.
#
# Holm, S. (1979). A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics 6, 65–70.
#
# Hommel, G. (1988). A stagewise rejective multiple test procedure based on a modified Bonferroni test. Biometrika 75, 383–386.
#
# Hochberg, Y. (1988). A sharper Bonferroni procedure for multiple tests of significance. Biometrika 75, 800–803.
#
# Shaffer, J. P. (1995). Multiple hypothesis testing. Annual Review of Psychology 46, 561–576. (An excellent review of the area.)
#
# Sarkar, S. (1998). Some probability inequalities for ordered MTP2 random variables: a proof of Simes conjecture. Annals of Statistics 26, 494–504.
#
# Sarkar, S., and Chang, C. K. (1997). Simes' method for multiple hypothesis testing with positively dependent test statistics. Journal of the American Statistical Association 92, 1601–1608.
#
# Wright, S. P. (1992). Adjusted P-values for simultaneous inference. Biometrics 48, 1005–1013.
#
# Bonferroni, C. E., Teoria statistica delle classi e calcolo delle probabilità, Pubblicazioni del R Istituto Superiore di Scienze Economiche e Commerciali di Firenze 1936
# Olive Jean Dunn, Estimation of the Medians for Dependent Variables, The Annals of Mathematical Statistics 1959 http://projecteuclid.org/download/pdf_1/euclid.aoms/1177706374
# Olive Jean Dunn, Multiple Comparisons Among Means, Journal of the American Statistical Association 1961 http://sci2s.ugr.es/keel/pdf/algorithm/articulo/1961-Bonferroni_Dunn-JASA.pdf
# plot p-values and adjusted p-values
tiff("pvals.tiff",width=8,height=8,units='in',res=300, compression = "lzw")
par(mfrow=c(6,1))
plot(pvals,ylim=c(0,1),pch=16,xlab="",ylab="p-values",cex.lab=1.5)
abline(h=0.05,lty=2)
plot(padj,ylim=c(0,1),pch=16,xlab="",ylab="bonferroni",cex.lab=1.5)
abline(h=0.05,lty=2)
## alternative p adjust
padj<-p.adjust(pvals, method = "holm", n = length(pvals))
plot(padj,ylim=c(0,1),pch=16,xlab="",ylab="holm",cex.lab=1.5)
abline(h=0.05,lty=2)
## alternative p adjust
padj<-p.adjust(pvals, method = "hochberg", n = length(pvals))
plot(padj,ylim=c(0,1),pch=16,xlab="",ylab="hochberg",cex.lab=1.5)
abline(h=0.05,lty=2)
## alternative p adjust
padj<-p.adjust(pvals, method = "BH", n = length(pvals)) # same as fdr
plot(padj,ylim=c(0,1),pch=16,xlab="",ylab="BH",cex.lab=1.5)
abline(h=0.05,lty=2)
## alternative p adjust
padj<-p.adjust(pvals, method = "BY", n = length(pvals)) # same as fdr
plot(padj,ylim=c(0,1),pch=16,ylab="BY",cex.lab=1.5,xlab="sample number")
abline(h=0.05,lty=2)
dev.off()
##
# Bonferroni correction ("bonferroni")
# in which the p-values are multiplied by the number of comparisons.
# Less conservative corrections are also included by Holm (1979) ("holm"),
# Hochberg (1988) ("hochberg"), Hommel (1988) ("hommel"),
# Benjamini & Hochberg (1995) ("BH" or its alias "fdr"),
# and Benjamini & Yekutieli (2001) ("BY"), respectively.
# Benjamini, Y., and Hochberg, Y. (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal Statistical Society Series B 57, 289–300.
tiff("pvals.tiff",width=8,height=8,units='in',res=300, compression = "lzw")
par(mfrow=c(6,1))
par(oma=c(0.1,1,0.1,0.2))
par(mar=c(2,5,2,2))
plot(pvals,ylim=c(0,1),pch=16,xlab="",ylab="p-values",cex.lab=1.5)
abline(h=0.05,lty=2)
plot(padj,ylim=c(0,1),pch=16,xlab="",ylab="bonferroni",cex.lab=1.5)
abline(h=0.05,lty=2)
## alternative p adjust
padj<-p.adjust(pvals, method = "holm", n = length(pvals))
plot(padj,ylim=c(0,1),pch=16,xlab="",ylab="holm",cex.lab=1.5)
abline(h=0.05,lty=2)
## alternative p adjust
padj<-p.adjust(pvals, method = "hochberg", n = length(pvals))
plot(padj,ylim=c(0,1),pch=16,xlab="",ylab="hochberg",cex.lab=1.5)
abline(h=0.05,lty=2)
## alternative p adjust
padj<-p.adjust(pvals, method = "BH", n = length(pvals)) # same as fdr
plot(padj,ylim=c(0,1),pch=16,xlab="",ylab="BH",cex.lab=1.5)
abline(h=0.05,lty=2)
## alternative p adjust
padj<-p.adjust(pvals, method = "BY", n = length(pvals)) # same as fdr
plot(padj,ylim=c(0,1),pch=16,ylab="BY",cex.lab=1.5,xlab="sample number")
abline(h=0.05,lty=2)
dev.off()
##
tiff("pvals.tiff",width=8,height=8,units='in',res=300, compression = "lzw")
par(mfrow=c(6,1))
par(oma=c(1,1,0.1,0.2))
par(mar=c(2,5,2,2))
plot(pvals,ylim=c(0,1),pch=16,xlab="",ylab="p-values",cex.lab=1.5)
abline(h=0.05,lty=2)
plot(padj,ylim=c(0,1),pch=16,xlab="",ylab="bonferroni",cex.lab=1.5)
abline(h=0.05,lty=2)
## alternative p adjust
padj<-p.adjust(pvals, method = "holm", n = length(pvals))
plot(padj,ylim=c(0,1),pch=16,xlab="",ylab="holm",cex.lab=1.5)
abline(h=0.05,lty=2)
## alternative p adjust
padj<-p.adjust(pvals, method = "hochberg", n = length(pvals))
plot(padj,ylim=c(0,1),pch=16,xlab="",ylab="hochberg",cex.lab=1.5)
abline(h=0.05,lty=2)
## alternative p adjust
padj<-p.adjust(pvals, method = "BH", n = length(pvals)) # same as fdr
plot(padj,ylim=c(0,1),pch=16,xlab="",ylab="BH",cex.lab=1.5)
abline(h=0.05,lty=2)
## alternative p adjust
padj<-p.adjust(pvals, method = "BY", n = length(pvals)) # same as fdr
plot(padj,ylim=c(0,1),pch=16,ylab="BY",cex.lab=1.5,xlab="sample number")
abline(h=0.05,lty=2)
dev.off()
rm(list=ls())
library(waveslim)
library(dplR)
library(xts)
library(wavelets)
library(wavethresh)
library(gplots)
## simulate cycles with frequency change and see what happens
##########################
##
## Poisson
##
TIME<-1:1000
w<-rpois(1000,lambda=20)
plot(1:1000,w)
test<-morlet(w, x1 = seq_along(w), p2 = NULL, dj = 0.25, siglvl = 0.95)
wavelet.plot(test)
acf(w, lag.max = length(w),plot=T,main="")
Seasonal<-3*sin(2*pi*TIME/100)+2*sin(2*pi*TIME/100)#+0.1*sin(2*pi*4*TIME/14)+0.1*cos(2*pi*4*TIME/14)
x<-Seasonal+w
plot(Seasonal)
plot(x)#,type="l")
#test<-morlet(x, x1 = seq_along(x), p2 = NULL, dj = 0.25, siglvl = 0.95)
#wavelet.plot(test)
kappa=20; s=25; omega=10;phi=0; t=TIME
peaks<-(kappa*(1/sqrt((1/s)*pi)*exp(-((cos(pi*omega*t/1000-phi))^2)/(1/s))))
plot(peaks,type="l")
x3<-peaks+Seasonal+w
plot(x3)#,type="l")
test<-morlet(x3, x1 = seq_along(x3), p2 = NULL, dj = 0.25, siglvl = 0.95)
wavelet.plot(test)
acf(x3, lag.max = length(x3),plot=T,main="")
trend<-0.05*TIME
x4<-peaks+Seasonal+w+trend
plot(x4)#,type="l")
test<-morlet(x4, x1 = seq_along(x4), p2 = NULL, dj = 0.25, siglvl = 0.95)
wavelet.plot(test)
plot(1:1000,w,
#type="l",
ylim=c(0,350),axes="n")
lines(1:1000,Seasonal+80)
lines(1:1000,peaks+120)
lines(1:1000,trend+200)
points(1:1000,x4+220)
mtext(2,text="Signal",line=2,cex=1)
#mtext(2,text="Random  Daily Periodic  Trend Combined",line=1,at=c(25),cex=0.8)
acf(x4, lag.max = length(x4),plot=T,main="")
max(x4)
min(x4)
spos<-x4
sneg<-300-x4
plot(spos/(spos+sneg),type="l",ylab="Proportion seropositive")
plot(100*spos/(spos+sneg),type="l",ylab="Seroprevalence (%)")
###########
## data and confidence intervals
sp<-spos/(spos+sneg)
tot<-spos+sneg
res.new<-rbind(round(spos,0),tot,sp)
rownames(res.new)<-c("P","N","Sp")
res.new<-t(res.new)
class(res.new)
res.u<-matrix(NA,ncol=1000,nrow=2)
for (ii in 1:1000){
res.u[1,ii]<-binom.test(res.new[ii],res.new[ii+1000])$conf.int[1]
res.u[2,ii]<-binom.test(res.new[ii],res.new[ii+1000])$conf.int[2]
}
res.u<-t(res.u)
res.all<-cbind(res.new,res.u)
dim(res.all)
colnames(res.all)<-c("P","N","Sp","L","U")
res.all<-as.data.frame(res.all)
## each sample get CIs
barplot(res.all$Sp,ylim=c(0,1))
barplot2(res.all$Sp, plot.ci=TRUE, ci.l=res.all$L, ci.u=res.all$U,
ylim=c(0,1),main="",ci.lty=2)#,names.arg=c(1:20))
barplot2(res.all$Sp[1:10], plot.ci=TRUE, ci.l=res.all$L[1:10], ci.u=res.all$U[1:10],
ylim=c(0,1),main="",ci.lty=2)#,names.arg=c(1:20))
####
barplot2(res.all$Sp[c(1,100,150,300,1000)], plot.ci=TRUE, ci.l=res.all$L[c(1,100,150,300,1000)], ci.u=res.all$U[c(1,100,150,300,1000)],
ylim=c(0,1),main="",ci.lty=2)#,names.arg=c(1:20))
## to here
res.P<-res.all$P[c(1,100,150,300,1000)]
res.T<-res.all$N[c(1,100,150,300,1000)]
res.N<-res.T-res.P
## chi squared test
prop.test(res.P,res.N)
res.data<-cbind(res.P,res.N)
chisq.test(res.data)
res.SP<-res.P/res.T
t<-1:5
lmres<-lm(res.SP~t)
abline(lmres,col="red",
lty=2)
####
#acf(res.all$Sp, lag.max = length(res.all$Sp),plot=T,main="")
#acf(res.SP)
par(mfrow=c(2,4))
acf(res.all$Sp[seq(from=1,to=1000,by=100)], lag.max = length(res.all$Sp[seq(from=1,to=1000,by=100)]),plot=T,main="")
barplot2(res.all$Sp[seq(from=1,to=1000,by=100)], plot.ci=TRUE, ci.l=res.all$L[seq(from=1,to=1000,by=100)], ci.u=res.all$U[seq(from=1,to=1000,by=100)],
ylim=c(0,1),main="",ci.lty=2)#,names.arg=c(1:20))
lmres<-lm(res.all$Sp[seq(from=1,to=1000,by=100)]~seq(from=1,to=10))
abline(lmres,col="red",
lty=2,lwd=2)
pt<-prop.test(res.all$P[seq(from=1,to=1000,by=100)],res.all$N[seq(from=1,to=1000,by=100)])
text(expression(paste(chi^2, "=")),x=length(seq(from=1,to=1000,by=100))/2,y=0.8)
text(round(pt$statistic,0),x=length(seq(from=1,to=1000,by=100))/2,y=0.7)
text(expression(paste("p-value =")),x=length(seq(from=1,to=1000,by=100))/2,y=0.6)
text(signif(pt$p.value,2),x=length(seq(from=1,to=1000,by=100))/2,y=0.5)
acf(res.all$Sp[seq(from=1,to=1000,by=10)], lag.max = length(res.all$Sp[seq(from=1,to=1000,by=10)]),plot=T,main="")
barplot2(res.all$Sp[seq(from=1,to=1000,by=10)], plot.ci=TRUE, ci.l=res.all$L[seq(from=1,to=1000,by=10)], ci.u=res.all$U[seq(from=1,to=1000,by=10)],
ylim=c(0,1),main="",ci.lty=2)#,names.arg=c(1:20))
lmres<-lm(res.all$Sp[seq(from=1,to=1000,by=10)]~seq(from=1,to=100))
abline(lmres,col="red",
lty=2,lwd=2)
pt<-prop.test(res.all$P[seq(from=1,to=1000,by=10)],res.all$N[seq(from=1,to=1000,by=10)])
text(expression(paste(chi^2, "=")),x=length(seq(from=1,to=1000,by=10))/2,y=0.8)
text(round(pt$statistic,0),x=length(seq(from=1,to=1000,by=10))/2,y=0.7)
text(expression(paste("p-value =")),x=length(seq(from=1,to=1000,by=10))/2,y=0.6)
text(signif(pt$p.value,2),x=length(seq(from=1,to=1000,by=10))/2,y=0.5)
acf(res.all$Sp[seq(from=1,to=100,by=10)], lag.max = length(res.all$Sp[seq(from=1,to=100,by=10)]),plot=T,main="")
barplot2(res.all$Sp[seq(from=1,to=100,by=10)], plot.ci=TRUE, ci.l=res.all$L[seq(from=1,to=100,by=10)], ci.u=res.all$U[seq(from=1,to=100,by=10)],
ylim=c(0,1),main="",ci.lty=2)#,names.arg=c(1:20))
lmres<-lm(res.all$Sp[seq(from=1,to=100,by=10)]~seq(from=1,to=10))
abline(lmres,col="red",
lty=2,lwd=2)
pt<-prop.test(res.all$P[seq(from=1,to=100,by=10)],res.all$N[seq(from=1,to=100,by=10)])
text(expression(paste(chi^2, "=")),x=length(seq(from=1,to=100,by=10))/2,y=0.8)
text(round(pt$statistic,0),x=length(seq(from=1,to=100,by=10))/2,y=0.7)
text(expression(paste("p-value =")),x=length(seq(from=1,to=100,by=10))/2,y=0.6)
text(signif(pt$p.value,2),x=length(seq(from=1,to=100,by=10))/2,y=0.5)
acf(res.all$Sp[seq(from=1,to=100,by=5)], lag.max = length(res.all$Sp[seq(from=1,to=100,by=5)]),plot=T,main="")
barplot2(res.all$Sp[seq(from=1,to=100,by=5)], plot.ci=TRUE, ci.l=res.all$L[seq(from=1,to=100,by=5)], ci.u=res.all$U[seq(from=1,to=100,by=5)],
ylim=c(0,1),main="",ci.lty=2)#,names.arg=c(1:20))
lmres<-lm(res.all$Sp[seq(from=1,to=100,by=5)]~seq(from=1,to=20))
abline(lmres,col="red",
lty=2,lwd=2)
pt<-prop.test(res.all$P[seq(from=1,to=100,by=5)],res.all$N[seq(from=1,to=100,by=5)])
text(expression(paste(chi^2, "=")),x=length(seq(from=1,to=100,by=5))/2,y=0.8)
text(round(pt$statistic,0),x=length(seq(from=1,to=100,by=5))/2,y=0.7)
text(expression(paste("p-value =")),x=length(seq(from=1,to=100,by=5))/2,y=0.6)
text(signif(pt$p.value,2),x=length(seq(from=1,to=100,by=5))/2,y=0.5)
pos <- res.all$P[seq(from=1,to=100,by=5)]
neg <- res.all$N[seq(from=1,to=100,by=5)] - pos
# use chi-sq test
pt<-prop.test(pos, pos+neg)
# use GLM for the same thing
t   <- 1:20
mat <- cbind(pos, neg)
mod.glm <- glm(mat ~ as.factor(t), family="binomial")
anova(mod.glm, test="Chisq")
# ideally include auto-correlation, but this is too hard :(
#mod.glm <- glmer(mat ~ as.factor(t), family="binomial")
#anova(mod.glm, test="Chisq")
#glmmPQL(mat ~ as.factor(t), family="binomial", correlation=corAR1())
# testing autocorrelation
# NOTE here that we're assuming constant sample size across time.
# with different sample sizes we'd want to weight each datapoint by the (inverse of?) sample size
t <- 1:10
sp <- res.all$Sp[seq(from=1,to=1000,by=100)]
lmres<-lm(sp ~ t)
lmres2<-gls(sp~t, correlation=corAR1())
acf(res.all$Sp[seq(from=1,to=1000,by=100)], lag.max = length(res.all$Sp[seq(from=1,to=1000,by=100)]),plot=T,main="")
barplot2(res.all$Sp[seq(from=1,to=1000,by=100)], plot.ci=TRUE, ci.l=res.all$L[seq(from=1,to=1000,by=100)], ci.u=res.all$U[seq(from=1,to=1000,by=100)],
ylim=c(0,1),main="",ci.lty=2)#,names.arg=c(1:20))
lmres<-lm(res.all$Sp[seq(from=1,to=1000,by=100)]~seq(from=1,to=10))
abline(lmres,col="red",
lty=2,lwd=2)
abline(lmres2, col="blue")
pt<-prop.test(res.all$P[seq(from=1,to=1000,by=100)],res.all$N[seq(from=1,to=1000,by=100)])
text(expression(paste(chi^2, "=")),x=length(seq(from=1,to=1000,by=100))/2,y=0.8)
text(round(pt$statistic,0),x=length(seq(from=1,to=1000,by=100))/2,y=0.7)
text(expression(paste("p-value =")),x=length(seq(from=1,to=1000,by=100))/2,y=0.6)
text(signif(pt$p.value,2),x=length(seq(from=1,to=1000,by=100))/2,y=0.5)
x<-runif(100)
y<-runif(100)
par(pty="s")
plot(x,y,pch=16)
library(spatstat)
#install.packages("spatstat")
library(spatial)
spat.t<-ppp(x, y, c(0,1), c(0,1))
plot(spat.t)
plot(Kest(spat.t))
plot(envelope(spat.t,Kest))
# non-random
##
x1<-c(runif(50))
x2<-seq(0,1,by=0.1)
x3<-runif(15,min=0.1,max=0.2)
y1<-c(runif(50))
y2<-seq(0,1,by=0.1)
y3<-runif(15,min=0.1,max=0.2)
xall<-c(x1,x2,x3)
yall<-c(y1,y2,y3)
par(pty="s")
par(mfrow=c(2,2))
plot(xall,yall,pch=16,xlim=c(0,1),ylim=c(0,1))
plot(x1,y1,pch=16,xlim=c(0,1),ylim=c(0,1))
plot(x2,y2,pch=16,xlim=c(0,1),ylim=c(0,1))
plot(x3,y3,pch=16,xlim=c(0,1),ylim=c(0,1))
spat.t<-ppp(xall, yall, c(0,1), c(0,1))
plot(spat.t)
plot(Kest(spat.t))
par(mfrow=c(1,1))
plot(spat.t)
plot(Kest(spat.t))
par(mfrow=c(2,2))
plot(xall,yall,pch=16,xlim=c(0,1),ylim=c(0,1))
plot(x1,y1,pch=16,xlim=c(0,1),ylim=c(0,1))
plot(x2,y2,pch=16,xlim=c(0,1),ylim=c(0,1))
plot(x3,y3,pch=16,xlim=c(0,1),ylim=c(0,1))
spat.t<-ppp(xall, yall, c(0,1), c(0,1))
par(mfrow=c(1,1))
plot(spat.t)
plot(Kest(spat.t))
?Kest
plot(Kest(spat.t,correction=c("border")))
plot(envelope(spat.t,Kest))
?plot
?lm
?anova
?glm
?gls
??gls
plot(envelope(spat.t,Kest))
plot(envelope(spat.t,Kest(correction=c("border"))))
pos<-rpois(100,lambda=15)
neg<-100-pos
tot<-neg+pos
seropos<-pos/tot
#plot(seropos)
marks(spat.t) <- seropos
plot((spat.t),fg='grey',bg="grey",main="",
ylab="Y",'xlab="x')
pos<-seq(from=0.1,to=10,by=0.1)
neg<-100-pos
tot<-neg+pos
seropos<-pos/tot
w<-rlnorm(100,sd=0.5)
Z<-seq(from=0.1,to=10,by=0.1)+w
W<-rev(seq(from=0.1,to=10,by=0.1)+w)
V<-rep(1,100)+w
lin.m<-lm(seropos ~ Z)
summary(lin.m)
plot(seropos,Z)
lin.m<-lm(seropos ~ W)
summary(lin.m)
plot(seropos,W)
lin.m<-lm(seropos ~ V)
summary(lin.m)
plot(seropos,V)
lin.m<-lm(seropos ~ V*W*Z)
summary(lin.m)
marks(spat.t) <- seropos
plot((spat.t),fg='grey',bg="grey",main="",
ylab="Y",'xlab="x')
mean(seropos)
diff<-seropos-mean(seropos)
rbPal <- colorRampPalette(c('blue','red'))
dat<-data.frame(x,y,diff,seropos)
dat$Col <- rbPal(10)[as.numeric(cut(diff,breaks = 10))]
plot(dat$x,dat$y,pch = 20,col = dat$Col,cex=2)
text(dat$x, dat$y, round(dat$diff, 2), cex=0.8)
dat$Col <- rbPal(10)[as.numeric(cut(dat$seropos,breaks = 10))]
plot(dat$x,dat$y,pch = 20,col = dat$Col,cex=2)
text(dat$x, dat$y, round(dat$seropos, 2), cex=0.8)
plot(dat$x,dat$y,pch = 20,col = "white",cex=2)
text(dat$x, dat$y, round(dat$seropos, 2), cex=0.8)
plot(dat$x,dat$y,pch = 20,col = "white",cex=2)
text(dat$x, dat$y, round(dat$diff, 2), cex=0.8)
dat<-data.frame(x,y,diff,seropos,Z)
dat$Col <- rbPal(10)[as.numeric(cut(dat$Z,breaks = 10))]
plot(dat$x,dat$y,pch = 20,col = dat$Col,cex=2)
text(dat$x, dat$y, round(dat$Z, 2), cex=0.8)
plot(dat$Z,dat$seropos)
lmdat<-lm(dat$seropos~dat$Z+dat$y+dat$x)
summary(lmdat)
x<-runif(100)
y<-runif(100)
par(pty="s")
plot(x,y,pch=16)
library(spatstat)
#install.packages("spatstat")
library(spatial)
spat.t<-ppp(x, y, c(0,1), c(0,1))
plot(spat.t)
plot(Kest(spat.t))
plot(envelope(spat.t,Kest))
##
# non-random
x1<-c(runif(50))
x2<-seq(0,1,by=0.1)
x3<-runif(15,min=0.1,max=0.2)
y1<-c(runif(50))
y2<-seq(0,1,by=0.1)
y3<-runif(15,min=0.1,max=0.2)
xall<-c(x1,x2,x3)
yall<-c(y1,y2,y3)
par(pty="s")
par(mfrow=c(2,2))
plot(xall,yall,pch=16,xlim=c(0,1),ylim=c(0,1))
plot(x1,y1,pch=16,xlim=c(0,1),ylim=c(0,1))
plot(x2,y2,pch=16,xlim=c(0,1),ylim=c(0,1))
plot(x3,y3,pch=16,xlim=c(0,1),ylim=c(0,1))
spat.t<-ppp(xall, yall, c(0,1), c(0,1))
par(mfrow=c(1,1))
plot(spat.t)
plot(Kest(spat.t))
plot(envelope(spat.t,Kest))
## add serological data
pos<-rpois(100,lambda=15)
neg<-100-pos
tot<-neg+pos
seropos<-pos/tot
#plot(seropos)
marks(spat.t) <- seropos
plot((spat.t),fg='grey',bg="grey",main="",
ylab="Y",'xlab="x')
pos<-seq(from=0.1,to=10,by=0.1)
neg<-100-pos
tot<-neg+pos
seropos<-pos/tot
w<-rlnorm(100,sd=0.5)
Z<-seq(from=0.1,to=10,by=0.1)+w
W<-rev(seq(from=0.1,to=10,by=0.1)+w)
V<-rep(1,100)+w
lin.m<-lm(seropos ~ Z)
summary(lin.m)
plot(seropos,Z)
lin.m<-lm(seropos ~ W)
summary(lin.m)
plot(seropos,W)
lin.m<-lm(seropos ~ V)
summary(lin.m)
plot(seropos,V)
lin.m<-lm(seropos ~ V*W*Z)
summary(lin.m)
marks(spat.t) <- seropos
plot((spat.t),fg='grey',bg="grey",main="",
ylab="Y",'xlab="x')
mean(seropos)
diff<-seropos-mean(seropos)
rbPal <- colorRampPalette(c('blue','red'))
dat<-data.frame(x,y,diff,seropos)
dat$Col <- rbPal(10)[as.numeric(cut(diff,breaks = 10))]
plot(dat$x,dat$y,pch = 20,col = dat$Col,cex=2)
text(dat$x, dat$y, round(dat$diff, 2), cex=0.8)
dat<-data.frame(x,y,diff,seropos,Z)
dat$Col <- rbPal(10)[as.numeric(cut(dat$Z,breaks = 10))]
plot(dat$x,dat$y,pch = 20,col = dat$Col,cex=2)
text(dat$x, dat$y, round(dat$Z, 2), cex=0.8)
plot(dat$Z,dat$seropos)
lmdat<-lm(dat$seropos~dat$Z+dat$y+dat$x)
summary(lmdat)
dat<-data.frame(x,y,diff,seropos,Z)
dat$Col <- rbPal(10)[as.numeric(cut(dat$Z,breaks = 10))]
plot(dat$x,dat$y,pch = 20,col = dat$Col,cex=2)
text(dat$x, dat$y, round(dat$Z, 2), cex=0.8)
plot(dat$Z,dat$seropos)
Z<-seq(from=0.1,to=10,by=0.1)+w
W<-rev(seq(from=0.1,to=10,by=0.1)+w)
V<-rep(1,100)+w
lin.m<-lm(seropos ~ Z)
summary(lin.m)
plot(seropos,Z)
lin.m<-lm(seropos ~ W)
summary(lin.m)
plot(seropos,W)
lin.m<-lm(seropos ~ V)
summary(lin.m)
plot(seropos,V)
lin.m<-lm(seropos ~ V*W*Z)
summary(lin.m)
marks(spat.t) <- seropos
plot((spat.t),fg='grey',bg="grey",main="",
ylab="Y",'xlab="x')
mean(seropos)
diff<-seropos-mean(seropos)
rbPal <- colorRampPalette(c('blue','red'))
dat<-data.frame(x,y,diff,seropos)
dat$Col <- rbPal(10)[as.numeric(cut(diff,breaks = 10))]
plot(dat$x,dat$y,pch = 20,col = dat$Col,cex=2)
text(dat$x, dat$y, round(dat$diff, 2), cex=0.8)
dat$Col <- rbPal(10)[as.numeric(cut(dat$seropos,breaks = 10))]
plot(dat$x,dat$y,pch = 20,col = dat$Col,cex=2)
text(dat$x, dat$y, round(dat$seropos, 2), cex=0.8)
plot(dat$x,dat$y,pch = 20,col = "white",cex=2)
text(dat$x, dat$y, round(dat$seropos, 2), cex=0.8)
plot(dat$x,dat$y,pch = 20,col = "white",cex=2)
text(dat$x, dat$y, round(dat$diff, 2), cex=0.8)
dat<-data.frame(x,y,diff,seropos,Z)
dat$Col <- rbPal(10)[as.numeric(cut(dat$Z,breaks = 10))]
plot(dat$x,dat$y,pch = 20,col = dat$Col,cex=2)
text(dat$x, dat$y, round(dat$Z, 2), cex=0.8)
plot(dat$Z,dat$seropos)
lmdat<-lm(dat$seropos~dat$Z+dat$y+dat$x)
summary(lmdat)
plot(dat$x,dat$y,pch = 20,col = dat$Col,cex=2)
dat$Col <- rbPal(10)[as.numeric(cut(dat$seropos,breaks = 10))]
plot(dat$x,dat$y,pch = 20,col = dat$Col,cex=2)
dat$Col <- rbPal(10)[as.numeric(cut(dat$Z,breaks = 10))]
plot(dat$x,dat$y,pch = 20,col = dat$Col,cex=2)
dat$Col <- rbPal(10)[as.numeric(cut(dat$seropos,breaks = 10))]
plot(dat$x,dat$y,pch = 20,col = dat$Col,cex=2)
